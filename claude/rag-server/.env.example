# ========================================
# RAG MCP Server Environment Configuration
# Performance-Optimized Settings (v2024.12)
# ========================================

# ----------------------------------------
# Basic Configuration
# ----------------------------------------
NODE_ENV=development
DATA_DIR=./.data
DOCUMENTS_DIR=./documents

# Logging level: debug, info, warn, error
# Use 'debug' for troubleshooting, 'info' for production
LOG_LEVEL=info

# ----------------------------------------
# Document Processing (Optimized)
# ----------------------------------------
# Text chunking configuration
CHUNK_SIZE=400
CHUNK_OVERLAP=100
MIN_CHUNK_SIZE=300

# Chunking strategy: 'contextual' (AI-enhanced) or 'normal' (standard)
# Contextual provides better semantic chunking but requires more resources
CHUNKING_STRATEGY=normal

# Model for contextual chunking (context generation via Ollama)
CONTEXTUAL_CHUNKING_MODEL=qwen3:4b

# Maximum concurrent file processing 
# Reduced from 3 to 2 to prevent resource contention and improve stability
MAX_CONCURRENT_PROCESSING=2

# Maximum error history count for monitoring
MAX_ERROR_HISTORY=1000

# ----------------------------------------
# Ollama Configuration
# ----------------------------------------
# Ollama server URL - ensure Ollama is running on this endpoint
OLLAMA_BASE_URL=http://localhost:11434

# Embedding model (must be available in your Ollama server)
# Run: ollama pull qllama/multilingual-e5-large-instruct:latest
EMBEDDING_MODEL=qllama/multilingual-e5-large-instruct:latest

# ----------------------------------------
# Embedding Configuration (Performance Optimized)
# ----------------------------------------
# Batch size for embedding generation
# Increased from 8 to 12 for better throughput, automatically adapts based on model limits
EMBEDDING_BATCH_SIZE=12

# Embedding processing concurrency
# Optimized from 3 to 4 for better parallel processing without overwhelming Ollama
EMBEDDING_CONCURRENCY=4

# Embedding cache settings (handled automatically by the service)
# - Cache size: 1000 embeddings (LRU eviction)
# - Cache enables near-instant repeated document processing

# ----------------------------------------
# Vector Store Configuration
# ----------------------------------------
# LanceDB URI
LANCEDB_URI=./.data/lancedb

# ----------------------------------------
# Search Configuration
# ----------------------------------------
SEARCH_PIPELINE_TIMEOUT_MS=60000
SEMANTIC_SCORE_THRESHOLD=0.9

# ----------------------------------------
# File Watcher Configuration (Performance Optimized)
# ----------------------------------------
# File watcher debounce delay in milliseconds
# Reduced from 300ms to 200ms for faster response to file changes
WATCHER_DEBOUNCE_DELAY=200

# Maximum directory scan depth for recursive file discovery
WATCHER_MAX_SCAN_DEPTH=5

# Maximum files in processing queue
# Reduced from 100 to 50 to prevent memory issues with large document sets
WATCHER_MAX_PROCESSING_QUEUE=50

# File watcher features (automatically enabled):
# - Smart sync: Only processes new/changed files
# - Background processing: Non-blocking initialization
# - Duplicate detection: Prevents reprocessing unchanged files

# ----------------------------------------
# MCP Transport Configuration
# ----------------------------------------
# Transport: 'stdio' (default for Claude Desktop) or 'streamable-http'
MCP_TRANSPORT=streamable-http
MCP_PORT=3000
MCP_HOST=localhost
MCP_ENABLE_CORS=true
MCP_SESSION_TIMEOUT=300000
MCP_ALLOWED_ORIGINS=*
MCP_DNS_REBINDING_PROTECTION=false

# MCP Connection Timeouts (in milliseconds)
MCP_CONNECTION_TIMEOUT_MS=120000
MCP_KEEP_ALIVE_TIMEOUT_MS=65000
MCP_REQUEST_TIMEOUT_MS=90000

